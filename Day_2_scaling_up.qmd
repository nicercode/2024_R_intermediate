---
title: "Day 2 - Scaling up your computations"
format: html
---

# Introduction

The goal of this session is to collaboratively solve a series of challenges that will introduce you to practices that enable you scale up your computations.

The data

- (Re)introduce the Penguins data (Will)

A common challenge: Repeating things

- split, apply, combine (Dan)

Tools

- tidyverse: tables, group_by, summarise/mutate (Fonti)
- map: for lists / vectors (Dan)
- ggplot: facets 
- functions (Fonti)


--------------
Challenges (delete once migarted down)

- tidy data: tidyr pivot longer / pivot wider (Country )
- dplyr: join, group_by
- map, nest (Daniel)
- expand.grid Penguin x Source (Daniel)
- Functions
    - types: anonymous, named
    - when we use functions
    - map workflows
    - Nest workflow
- longer functions

## Load libraries

We will primarily be using packages from the {tidyverse}, feel free to add more packages here to help solve the challenges.
```{r}
library(tidyverse)
```


## All - Loading data from many files

<!-- map -->

We have just returned from an expedition from Anatarcia and collected *a lot* of data from multiple species of penguins. Sometimes "we" counted the penguins.  Sometimes we didn't.  We recorded data for each species in separate `.csv` files but **we need to combine these into one large dataframe for analyses. How can we do this programmatically?** 


In words, describe what are the steps to solve the challenge: 

- 
- 
- 

How would you solve this problem using existing knowledge: 

-
-
-

Try solving this in R using new skills:

```{r, learner-solutions}

```

Demonstrator solutions: 
```{r, instructor-solutions}
# Map workflow for read_csv
penguins_combined <- list.files("data/penguin_distributions", pattern=".csv",full.names = TRUE) |> 
  map(read_csv, show_col_types = FALSE) |> 
  list_rbind()

# write_csv(data, "data/penguins_combined.csv")
```


## Challenge 1 - Import common names

<!-- join -->

We only have latin names for each species of penguin but we need common names for when we report our results to stakeholders. Our collaborator started compiling common names in a separate `.csv` in the `data/` folder. **Compile the common names for the remaining taxa and join these into the dataframe `penguins_combined`. You may need to import the `penguins_combined.csv` into R first. 

In words, describe what are the steps to solve the challenge: 

- 
- 
- 

How would you solve this problem using existing knowledge: 

-
-
-

Try solving this in R using new skills:

```{r, learner-solutions}

```

Demonstrator solutions: 

```{r, instructor-solutions}
# Read in combined dataset
penguins_combined <- read_csv("data/penguin_combined.csv")

# Read in common names
penguins_common_names <- read_csv("data/penguin_common_names.csv")

# Join in common names
penguins_combined_with_common_names <- penguins_combined |> 
  left_join(penguins_common_names,  by = join_by(species == scientific_name))
```

## Challenge 2 - Add Size information (Fonti)

<!-- Group by summarise, join -->

We need to get compute the average bill and flipper dimensions using the `penguin_sizes` data and nd merge this into the `penguins_combined` dataset. You name need to wrangle/create the penguin names a little

In words, describe what are the steps to solve the challenge: 

- 
- 
- 

How would you solve this problem using existing knowledge: 

-
-
-

Try solving this in R using new skills:

```{r, learner-solutions}

```

Demonstrator solutions: 

```{r, instructor-solutions}
# Read in combined dataset
penguins_combined <- read_csv("data/penguin_combined.csv")

# Read in common names
penguins_common_names <- read_csv("data/penguin_common_names.csv")

# Join in common names
penguins_combined_with_common_names <- penguins_combined |> 
  left_join(penguins_common_names,  by = join_by(species == scientific_name))

# Read in body mass
penguin_size <- read_csv("data/penguin_sizes.csv")

# Join in taxonomic information
penguin_size$species |> unique()

penguin_size_new_name <- penguin_size |> 
  mutate(full_common_name = paste(species, "penguin")) |> 
  select(full_common_name, species:year)

penguin_size_new_name |> count(full_common_name)

penguin_averages <- penguin_size_new_name |> 
  group_by(full_common_name) |> 
  summarise(mean_bill_length_mm = mean(bill_length_mm, na.rm = TRUE),
            mean_bill_depth_mm = mean(bill_depth_mm, na.rm = TRUE),
            mean_flipper_length_mm = mean(flipper_length_mm, na.rm = TRUE)
            ) 

# Join bill dimensions
penguins_combined_with_common_names |> count(common_name)

# Check if names exist
unique(penguins_combined_with_common_names$common_name)

unique(penguin_size_new_name$full_common_name)

# Join bill data
penguins_combined_with_common_names |> 
  left_join(penguin_averages, 
            by = join_by(common_name == full_common_name))
```

## Challenge 3 - Lots of descriptive statistics (Fonti)

We need to report on some descriptive statistics of our penguin study. We need to know the following:

- How many different genera are represented in our dataset
- How many different species do we have for each genera
- Calculate the proportion of points from iNaturalist and eBird using the institutionCode (the code for eBird is confusingly "CLO"; the code for iNaturalist is more sensibly "iNaturalist")
- How many records by species
- How many records by year
- How many records by country code
- How many records by basis of record

<!-- Group by summarise -->

In words, describe what are the steps to solve the challenge: 

- 
- 
- 

How would you solve this problem using existing knowledge: 

-
-
-

Try solving this in R using new skills:

```{r, learner-solutions}

```

Demonstrator solutions: 

```{r, instructor-solutions}
# Read in combined dataset
penguins_combined <- read_csv("data/penguin_combined.csv")

# Records x genus
penguins_combined |> 
  count(genus)

# Species x genus
penguins_combined |> 
  group_by(genus) |> 
  summarise(n_species = n_distinct(species))

# Species
penguins_combined |> 
    group_by(species) |> 
    summarise(n = n())


# A function for how summarise records by variable
summarise_records_by <- function(data, var_name){
  data |> 
    group_by({{var_name}}) |> 
    summarise(n = n())
}

penguins_combined |> 
  summarise_records_by(year)

penguins_combined |> 
  summarise_records_by(countryCode)

penguins_combined |> 
  summarise_records_by(basisOfRecord)
```

## Challenge 4 - Add n_records as a column (Daniel)

For your analysis, you need to calculate the total number of records available for each species, and add that as a new column in your data.

In words, describe what are the steps to solve the challenge: 

- 
- 
- 

How would you solve this problem using existing knowledge: 

-
-
-

Try solving this in R using new skills:

```{r, learner-solutions}

```

Demonstrator solutions: 

```{r, instructor-solutions}
# Read in combined dataset
penguins_combined <- read_csv("data/penguin_combined.csv")

penguins_combined_n_records <- penguins_combined |> 
  group_by(species) |> 
  mutate(n_records = n()) |> 
  ungroup()

# write_csv(penguins_combined_n_records, "data/penguins_combined_n_records_by_species.csv")
```


## Challenge 5 - Determine the top 3 most recorded taxa 

<!-- nest, slice_max, ggplot -->

In words, describe what are the steps to solve the challenge: 

- 
- 
- 

How would you solve this problem using existing knowledge: 

-
-
-

Try solving this in R using new skills:

```{r, learner-solutions}

```

Demonstrator solutions: 

```{r, instructor-solutions}
penguins_combined_n_records_by_species <- read_csv("data/penguins_combined_n_records_by_species.csv")

penguins_combined_n_records_by_species |> 
  distinct(species, n_records) |> 
  slice_max(order_by = n_records, n = 3) 
```

## Challenge 6 - Facet plot and export plots (Will)

In words, describe what are the steps to solve the challenge: 

- 
- 
- 

How would you solve this problem using existing knowledge: 

-
-
-

Try solving this in R using new skills:

```{r, learner-solutions}

```

Demonstrator solutions: 

```{r, instructor-solutions}

```

## Challenge 7 - Excluding rogue data (Fonti)

We need to clean the data a little before we analyse it. Exclude the following: 

-  Observations older than 1930
-  Individual counts < 0
- 


In words, describe what are the steps to solve the challenge: 

- 
- 
- 

How would you solve this problem using existing knowledge: 

-
-
-

Try solving this in R using new skills:

```{r, learner-solutions}

```

Demonstrator solutions: 

```{r, instructor-solutions}

```



## Challenge 8 - Save lots of data by year (Fonti)

In words, describe what are the steps to solve the challenge: 

- 
- 
- 

How would you solve this problem using existing knowledge: 

-
-
-

Try solving this in R using new skills:

```{r, learner-solutions}

```

Demonstrator solutions: 

```{r, instructor-solutions}

```


## Challenge 9 - A full matrix of observations (Daniel)

In words, describe what are the steps to solve the challenge: 

- 
- 
- 

How would you solve this problem using existing knowledge: 

-
-
-

Try solving this in R using new skills:

```{r, learner-solutions}

```

Demonstrator solutions: 

```{r, instructor-solutions}

```


## Challenge 10 - Make a lot of maps (Will)

In words, describe what are the steps to solve the challenge: 

- 
- 
- 

How would you solve this problem using existing knowledge: 

-
-
-

Try solving this in R using new skills:

```{r, learner-solutions}

```

Demonstrator solutions: 

```{r}
make_plot <- function(penguin_of_interest, pen_all = pen_all) {
  world <- map_data("world")
  specific_pen <- filter(pen_all, species == penguin_of_interest)
  pen_large_counts <- filter(specific_pen, individualCount >= 1000)
  pen_small_counts <- filter(specific_pen, individualCount < 1000)
  worldplot <- ggplot() +
    geom_polygon(data = world, aes(x = long, y = lat, group = group), fill= "grey") +
    coord_fixed(1.3) +
    geom_point(
      data = pen_small_counts,
      aes(x = decimalLongitude, y = decimalLatitude),
      col = "red",
      alpha = 0.1
    ) +
    geom_point(
      data = pen_large_counts,
      aes(x = decimalLongitude, y = decimalLatitude),
      col = "red"
    ) +
    ggtitle(penguin_of_interest) +
    theme_void()
  print(worldplot)
  return(worldplot)
}


make_plot(unique(data$species)[10], data)
```


Now let's use our new skills to make lots of plots!

```{r}
penguin_species <- unique(data$species)
walk(penguin_species, make_plot, data)
```

Or we could save the plots
```{r}
save_plot <- function(penguin_of_interest_in, pen_all, path = "output/by_species/") {
  dir.create(path, FALSE, TRUE)
  p <- make_plot(penguin_of_interest_in, pen_all)
  ggsave(paste0(path, penguin_of_interest, ".png"), p)
}

for (penguin_of_interest in penguin_species) {
  save_plot(penguin_of_interest, data)
}
```

## Challenge 11 - Fit lots of models (Daniel)

In words, describe what are the steps to solve the challenge: 

- 
- 
- 

How would you solve this problem using existing knowledge: 

-
-
-

Try solving this in R using new skills:

```{r, learner-solutions}

```

Demonstrator solutions: 

```{r, instructor-solutions}
only_counts <- filter(data, individualCount > 0)

fit_model <- function(data_in) {
  model <- lm(log10(individualCount) ~ decimalLatitude, data = data_in)
  return(model)
}


# take in a model object and return an r2 value
get_r2 <- function(fit_in) {
  r <- performance::r2(fit_in)
  return(r$R2)
}

pen_species<-unique(data$species)
just_one_penguin<-filter(data,species==pen_species[1])
one_penguin_model<-fit_model(just_one_penguin)
get_r2(one_penguin_model)

fits <-
  only_counts |>
  split(~species) |>
  map(fit_model)

map_dbl(fits, get_r2)

map_dbl(fits, ~performance::r2(.x)$R2)
map_dbl(fits, ~performance::r2(.x)[["R2"]])


map_dbl(fits, ~performance::r2(.x)[["R2"]])


performance::r2(fits[[1]]) %>% names()

performance::check_model(fits[[4]])

```

## Challenge 12 - Migratory Penguins

In words, describe what are the steps to solve the challenge: 

- 
- 
- 

How would you solve this problem using existing knowledge: 

-
-
-

Try solving this in R using new skills:

```{r, learner-solutions}

```


```{r, instructor-solutions}

```



